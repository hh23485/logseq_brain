tags:: [[Spark Action]]

- # 常见的 Action
	- ## [[count]]，[[countByKey]] 和 [[countByValue]] 操作
	  collapsed:: true
		- `count(): long`
			- 语义: 统计`rdd1`中包含的 record 个数, 返回一个 `long` 类型
			- 用法: `val result = rdd1.count()`
			- ![image.png](../assets/image_1680689449062_0.png){:height 446, :width 582}
				- `count()` 操作首先计算每个分区中 record 的数目,然后在 Driver 端进行累加操作, 得到最终结果
		- `countByKey(): Map[K, long]`
			- 语义: 统计 `rdd1` 中每个 `Key` 出现的次数 (`Key`可能有重复), 返回一个 `Map`, 要求 `rdd1` 是 `<K,V>` 类型
			- ![image.png](../assets/image_1680689580867_0.png){:height 304, :width 916}
				- 首先利用 [[mapValues]] 操作将 `<K,V>` record 的 `Value` 设置为 1
				- 然后利用 [[reduceByKey]] 统计每个`Key` 出现的次数
		- `countByValue():Map[T, long]`
			- 语义:统计`rdd`中每个 record 出现的次数,返回一个`Map`, 最后汇总到 Driver 端,形成 `Map`
			- ![image.png](../assets/image_1680689966066_0.png){:height 323, :width 921}
				- 先将 record 变为`<record, null>`类型
				- 使用 [[reduceByKey]] 得到每个 record 出现的次数
		-
	- ## [[collect]] 和 [[collectAsMap]] 操作
		- `collect(): Array[T]`
			- 用法: `val result = rdd1.collect()`
			- 语义: 将 `rdd1` 中的 record 收集到 Driver 端
		- `collectAsMap(): Map[K, V]`
			- 用法: `val result = rddl.collectAsMap()`
			- 语义: 将`rdd1`中的 `<K,V>` record收集到 Driver 端,得到 `<K,V> Map`
	- ## [[foreach]] 和 [[foreachPartition]]()
		- `foreach(func): Unit`
			- 语义:将`rdd1`中的每个分区中的数据按照 `func` 进行处理
		- `foreachPartition(func): Unit`
			- 语义: 将 `rdd1` 中的每个 record 按照`func`进行处理
			- [[foreach]] 和 [[foreachPartition]] 的关系类似于 [[map]] 和 [[mapPartitions]] 的关系
	- ## [[fold]]/[[reduce]]/ [[foldByKey]] 操作
		-